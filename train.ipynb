{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HoDa7tGE_ZF"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Extremely Minimalistic Implementation of DDPM\n",
        "https://arxiv.org/abs/2006.11239\n",
        "Everything is self contained. (Except for pytorch and torchvision... of course)\n",
        "\"\"\"\n",
        "\n",
        "from typing import Dict, Tuple\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFduuOpdkVpK"
      },
      "outputs": [],
      "source": [
        "def ddpm_schedules(beta1: float, beta2: float, T: int) -> Dict[str, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Returns pre-computed schedules for DDPM sampling, training process.\n",
        "    \"\"\"\n",
        "    assert beta1 < beta2 < 1.0, \"beta1 and beta2 must be in (0, 1)\"\n",
        "\n",
        "    beta_t = (beta2 - beta1) * torch.arange(0, T + 1, dtype=torch.float32) / T + beta1\n",
        "    sqrt_beta_t = torch.sqrt(beta_t)\n",
        "    alpha_t = 1 - beta_t\n",
        "    alphabar_t = torch.cumprod(alpha_t, dim=0)\n",
        "\n",
        "    return {\n",
        "        \"alpha_t\": alpha_t,\n",
        "        \"sqrt_beta_t\": sqrt_beta_t,\n",
        "        \"alphabar_t\": alphabar_t,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7TR3HSi2iZr",
        "outputId": "6f244c31-3536-4701-e1c4-4ea764716563"
      },
      "outputs": [],
      "source": [
        "print(ddpm_schedules(beta1=1e-4, beta2=0.02, T=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho4sNEygEzPA"
      },
      "outputs": [],
      "source": [
        "class DDPM(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        autoencoder_model: nn.Module,\n",
        "        betas: Tuple[float, float],\n",
        "        n_T: int,\n",
        "        criterion: nn.Module = nn.MSELoss(),\n",
        "    ) -> None:\n",
        "        super(DDPM, self).__init__()\n",
        "        self.autoencoder_model = autoencoder_model\n",
        "\n",
        "        # register_buffer allows us to freely access these tensors by name. It helps device placement.\n",
        "        for k, v in ddpm_schedules(betas[0], betas[1], n_T).items():\n",
        "            self.register_buffer(k, v)\n",
        "\n",
        "        self.n_T = n_T\n",
        "        self.criterion = criterion\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Implements Algorithm 1 from the paper.\n",
        "        Makes forward diffusion x_t, and tries to guess epsilon value from x_t using autoencoder_model.\n",
        "        \"\"\"\n",
        "\n",
        "        t = torch.randint(1, self.n_T, (x.shape[0],)).to(x.device)  # t ~ Uniform(0, n_T)\n",
        "        eps = torch.randn_like(x)  # eps ~ N(0, 1)\n",
        "\n",
        "        x_t = (\n",
        "            torch.sqrt(self.alphabar_t[t, None, None, None]) * x\n",
        "            + torch.sqrt(1 - self.alphabar_t[t, None, None, None]) * eps\n",
        "        )\n",
        "\n",
        "        return self.criterion(eps, self.autoencoder_model(x_t, t / self.n_T))\n",
        "\n",
        "    def sample(self, n_sample: int, size, device) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Implements Algorithm 2 from the paper.\n",
        "        \"\"\"\n",
        "\n",
        "        x_i = torch.randn(n_sample, *size).to(device)  # x_T ~ N(0, 1)\n",
        "\n",
        "        for i in range(self.n_T, 0, -1):\n",
        "            z = torch.randn(n_sample, *size).to(device) if i > 1 else 0\n",
        "            eps = self.autoencoder_model(x_i, i / self.n_T)\n",
        "            x_i = (\n",
        "                (1 / torch.sqrt(self.alpha_t[i])) *\n",
        "                (x_i - eps * (1 - self.alpha_t[i]) / torch.sqrt(1 - self.alphabar_t[i]))\n",
        "                + self.sqrt_beta_t[i] * z\n",
        "            )\n",
        "\n",
        "        return x_i\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueofC9Q4ag_9"
      },
      "outputs": [],
      "source": [
        "blk = lambda ic, oc: nn.Sequential(\n",
        "    nn.Conv2d(ic, oc, 7, padding=3),\n",
        "    nn.BatchNorm2d(oc),\n",
        "    nn.LeakyReLU(),\n",
        ")\n",
        "\n",
        "class AutoEncoderModel(nn.Module):\n",
        "    \"\"\"\n",
        "    This should be unet-like, but let's don't think about the model too much :P\n",
        "    Basically, any universal R^n -> R^n model should work.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_channel: int) -> None:\n",
        "        super(AutoEncoderModel, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            blk(n_channel, 64),\n",
        "            blk(64, 128),\n",
        "            blk(128, 256),\n",
        "            blk(256, 512),\n",
        "            blk(512, 256),\n",
        "            blk(256, 128),\n",
        "            blk(128, 64),\n",
        "            nn.Conv2d(64, n_channel, 3, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, t) -> torch.Tensor:\n",
        "        # Lets think about using t later. Paper uses positional embeddings.\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q49Ks5EuE9Kt"
      },
      "outputs": [],
      "source": [
        "import tonic\n",
        "import torchvision\n",
        "\n",
        "def train_frames(epochs:int=100, diffusion_steps:int=1000, lr=2e-4, device=\"cuda:0\", batch_size=12) -> None:\n",
        "\n",
        "    ddpm = DDPM(autoencoder_model=AutoEncoderModel(1), betas=(1e-4, 0.02), n_T=diffusion_steps)\n",
        "    ddpm.to(device)\n",
        "\n",
        "    transform=torchvision.transforms.Compose([\n",
        "        torch.as_tensor,\n",
        "        lambda x: x.float().unsqueeze(1) / x.max(),\n",
        "        torchvision.transforms.CenterCrop((180, 180)),\n",
        "        torchvision.transforms.Resize((90,90)),\n",
        "        torchvision.transforms.Normalize((0.5,), (0.5)),\n",
        "        ]) # convert to [-1, 1] range\n",
        "\n",
        "    def frame_transform(data):\n",
        "        events, imu, frames = data\n",
        "        frames = transform(frames['frames'])\n",
        "        return frames # events, imu,\n",
        "\n",
        "    dataset = tonic.datasets.DAVISDATA(save_to=\"data\", recording=[\"shapes_6dof\", \"shapes_translation\" , \"shapes_rotation\"], transform=frame_transform)\n",
        "    frames1 = dataset[0][0]\n",
        "    frames2 = dataset[1][0]\n",
        "    frames3 = dataset[2][0]\n",
        "    frames = torch.cat((frames1, frames2, frames3))\n",
        "    print(frames.shape)\n",
        "    dataloader = torch.utils.data.DataLoader(frames, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "    optim = torch.optim.Adam(ddpm.parameters(), lr=lr)\n",
        "\n",
        "    for i in range(epochs):\n",
        "        ddpm.train()\n",
        "\n",
        "        progress_bar = tqdm(dataloader)\n",
        "        loss_current = None\n",
        "        for x in progress_bar:\n",
        "            optim.zero_grad()\n",
        "            x = x.to(device)\n",
        "            loss = ddpm(x)\n",
        "            loss.backward()\n",
        "            if loss_current is None:\n",
        "                loss_current = loss.item()\n",
        "            else:\n",
        "                loss_current = 0.9 * loss_current + 0.1 * loss.item()\n",
        "            progress_bar.set_description(f\"loss: {loss_current:.4f}\")\n",
        "            optim.step()\n",
        "\n",
        "        ddpm.eval()\n",
        "        with torch.no_grad():\n",
        "            xh = ddpm.sample(4, (1, 90, 90), device)\n",
        "            grid = make_grid(xh, nrow=4)\n",
        "            save_image(grid, f\"./ddpm_sample_{i}.png\")\n",
        "            display(Image(f\"./ddpm_sample_{i}.png\", width=600, height=600))\n",
        "\n",
        "            # save model\n",
        "            torch.save(ddpm.state_dict(), f\"./ddpm_mnist.pth\")\n",
        "\n",
        "    display(Image(f\"./ddpm_sample_{epochs-1}.png\", width=448, height=448))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uuPYW37vFiJP"
      },
      "outputs": [],
      "source": [
        "train_frames(epochs=10, diffusion_steps=500) # diffusion_steps aka T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6PgLJS1GxSn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
